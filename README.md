# Awesome AI Engineer Reads

[üèóÔ∏è Building and Deploying LLMs](#-building-plus-deploying-llms)

[:balance_scale: Evaluating LLM + Retrieval](#evaluating-llm-plus-retrieval)

[:mag: LLM + Retrieval](#llm-and-retrieval)

[:computer: LLM Applications](#llm-applications)

[:brain: LLM Architectures and Models](#llm-architectures-and-models)

[:briefcase: LLM Business](#llm-business)

[:bar_chart: LLM Data](#llm-data)

[:rocket: LLM Deployment ](#llm-deployment)

[:jigsaw: LLM Embeddings](#llm-embeddings)

[:wrench: LLM Engineering](#llm-engineering)

[:trophy: LLM Engineering Best Practices](#llm-engineering-best-practices)

[:balance_scale: LLM Ethics and Governance](#llm-ethics-and-governance)

[:microscope: LLM Evaluation](#llm-evaluation)

[:ticket: LLM Events](#llm-events)

[:exploding_head: LLM Hype](#llm-hype)

[:thinking: LLM Inference](#llm-inference)

[:building_construction: LLM Infrastructure](#llm-infrastructure)

[:loudspeaker: LLM Marketing](#llm-marketing)

[:newspaper: LLM Newsletters](#llm-newsletters)

[:1234: LLM Numbers](#llm-numbers)

[:eyes: LLM Observability](#llm-observability)

[:speech_balloon: LLM Opinions and Critiques](#llm-opinions-and-critiques)

[:pencil: LLM Prompting](#llm-prompting)

[:notebook_with_decorative_cover: LLM Research and Publications](#llm-research-and-publications)

[:fishing_pole_and_fish: LLM Retriever Models](#llm-retriever-models)

[:moneybag: LLM Startups and Funding](#llm-startups-and-funding)

[:green_book: LLM Tutorials and Courses](#llm-tutorials-and-courses)

[:unlock: Open LLM Models](#open-llm-models)

[:wrench: Open LLM Tools](#open-llm-tools)

[:desktop_computer: Self-Hosted LLMs](#self-hosted-llms)

[:hammer_and_wrench: Tools and Frameworks](#tools-and-frameworks)

[:weight_lifting: Training and Fine-tuning LLMs](#training-and-fine-tuning-llms)

[:grey_question: Uncategorized](#uncategorized)

## Building and Deploying LLMs

- [Scaling Kubernetes to 7,500 nodes](https://openai.com/research/scaling-kubernetes-to-7500-nodes)
- [All the Hard Stuff Nobody Talks About when Building Products with LLMs](https://www.honeycomb.io/blog/hard-stuff-nobody-talks-about-llm)
- [All the Hard Stuff Nobody Talks About when Building Products with LLMs](https://www.honeycomb.io/blog/hard-stuff-nobody-talks-about-llm)
- [Building LLM applications for production](https://huyenchip.com/2023/04/11/llm-engineering.html)  
- [Efficiently Scaling and Deploying LLMs](https://home.mlops.communiy/home/videos/efficiently-scaling-and-deploying-llms)
- [LLMs in Production - Part III](https://home.mlops.community/public/events/llms-in-production-part-iii-2023-10-03)

## Training and Fine-tuning LLMs

- [How to train your own Large Language Models](https://blog.replit.com/llm-training)  
- [Training Compute-Optimal Large Language Models](https://arxiv.org/abs/2203.15556)
- [Opt-175B Logbook](https://github.com/facebookresearch/metaseq/blob/main/projects/OPT/chronicles/OPT175B_Logbook.pdf)
- [Fine-Tuning LLMs: Best Practices and When to Go Small](https://home.mlops.community/home/videos/fine-tuning-llms-best-practices-and-when-to-go-small-2023-06-02)  
- [Finetuning Large Language Models](https://www.deeplearning.ai/short-courses/finetuning-large-language-models/)
- [GPT-3.5 Turbo fine-tuning and API updates](https://openai.com/blog/gpt-3-5-turbo-fine-tuning-and-api-updates)
- [Fine-tuning in Your Voice Webinar](https://www.youtube.com/watch?v=MJm49TAyz5w)

## LLM Architectures and Models

- [A Survey of Large Language Models](https://arxiv.org/abs/2303.18223)
- [LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/abs/2302.13971?utm_source=www.turingpost.com&utm_medium=newsletter&utm_campaign=where-are-you-in-fmops-infrastructure-stack-tell-us)   
- [Introducing Code Llama, a state-of-the-art large language model for coding](https://ai.meta.com/blog/code-llama-large-language-model-coding/)
- [Spread Your Wings: Falcon 180B is here](https://huggingface.co/blog/falcon-180b)
- [BLOOM: A 176B-Parameter Open-Access Multilingual Language Model](https://arxiv.org/pdf/2211.05100.pdf?utm_source=www.turingpost.com&utm_medium=newsletter&utm_campaign=where-are-you-in-fmops-infrastructure-stack-tell-us)

## Tools and Frameworks

- [LangChain: Enabling LLMs to Use Tools](https://drive.google.com/file/d/1Z9wxwZRG8JOMkUfwDw7fD8sbijQ32J7W/view)  
- [Langchain Tutorials](https://github.com/gkamradt/langchain-tutorials)
- [LangChain cookbook](https://github.com/langchain-ai/langchain/tree/master/cookbook)
- [fairseq2](https://github.com/facebookresearch/fairseq2)
- [seamless_communication](https://github.com/facebookresearch/seamless_communication)

## LLM Applications  

- [Automatic Generation of Visualizations and Infographics with LLMs](https://microsoft.github.io/lida/)
- [Introducing AudioCraft: A Generative AI Tool For Audio and Music](https://about.fb.com/news/2023/08/audiocraft-generative-ai-for-music-and-audio/)
- [An example of LLM prompting for programming](https://martinfowler.com/articles/2023-chatgpt-xu-hao.html)   
- [Human-centric & Coherent Whole Program Synthesis aka your own personal junior developer](https://github.com/smol-ai/developer)
- [GPT Engineer](https://github.com/AntonOsika/gpt-engineer/)

## LLM Evaluation  

- [Holistic Evaluation of Language Models](https://github.com/stanford-crfm/helm) 
- [chatgpt-evaluation-01-2023](https://github.com/CLARIN-PL/chatgpt-evaluation-01-2023)
- [Evaluating chatGPT](https://ehudreiter.com/2023/04/04/evaluating-chatgpt/)
- [PromptBench: Towards Evaluating the Robustness of Large Language Models on Adversarial Prompts](https://arxiv.org/pdf/2306.04528.pdf)

## LLM Prompting

- [Prompt Engineering](https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/) 
- ["Prompt injection explained, with video, slides, and a transcript"](https://simonwillison.net/2023/May/2/prompt-injection-explained/)
- [Delimiters won‚Äôt save you from prompt injection](https://simonwillison.net/2023/May/11/delimiters-wont-save-you/)
- [You probably don't know how to do Prompt Engineering](https://gist.github.com/Hellisotherpeople/45c619ee22aac6865ca4bb328eb58faf)
- [ChatGPT Prompt Engineering for Developers](https://learn.deeplearning.ai/chatgpt-prompt-eng/lesson/2/guidelines)
- [Learn Prompting](https://learnprompting.org/docs/category/-basics)  

## LLM Research and Publications

- [A Survey of Large Language Models](https://arxiv.org/abs/2303.18223)
- [Challenges and Applications of Large Language Models](https://arxiv.org/abs/2307.10169) 
- [Large Language Models as Optimizers](https://arxiv.org/abs/2309.03409)
- [Multimodal Foundation Models: From Specialists to General-Purpose Assistants](https://arxiv.org/pdf/2309.10020.pdf)
- [Scaling Laws for Neural Language Models](https://arxiv.org/abs/2001.08361?utm_source=www.turingpost.com&utm_medium=newsletter&utm_campaign=where-are-you-in-fmops-infrastructure-stack-tell-us)
- [Language Models are Unsupervised Multitask Learners](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf?utm_source=www.turingpost.com&utm_medium=newsletter&utm_campaign=where-are-you-in-fmops-infrastructure-stack-tell-us)
- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805?utm_source=www.turingpost.com&utm_medium=newsletter&utm_campaign=where-are-you-in-fmops-infrastructure-stack-tell-us)
- [Training language models to follow instructions with human feedback](https://arxiv.org/abs/2203.02155?utm_source=www.turingpost.com&utm_medium=newsletter&utm_campaign=where-are-you-in-fmops-infrastructure-stack-tell-us)  

## LLM Embeddings

- [FlagEmbedding](https://huggingface.co/BAAI/bge-large-en-v1.5)
- [One Embedder, Any Task: Instruction-Finetuned Text Embeddings](https://github.com/xlang-ai/instructor-embedding)
- [OpenAI GPT-3 Text Embeddings - Really a new state-of-the-art in dense text embeddings?](https://medium.com/@nils_reimers/openai-gpt-3-text-embeddings-really-a-new-state-of-the-art-in-dense-text-embeddings-6571fe3ec9d9)  
- [Getting creative with embeddings](https://wattenberger.com/thoughts/yay-embeddings-math)
- [What are embeddings?](https://vickiboykis.com/what_are_embeddings/)

## LLM Retriever Models

- [Vector Databases and Large Language Models](https://drive.google.com/file/d/1SWUJEM8ZtsOPqrqW3b-Nn8HooPe9mgv8/view)
- [Large Language Models with Semantic Search](https://www.deeplearning.ai/short-courses/large-language-models-semantic-search/)  
- [MultiVector Retriever](https://python.langchain.com/docs/modules/data_connection/retrievers/multi_vector)  
- [Fine-Tuning LLaMA for Multi-Stage Text Retrieval](https://arxiv.org/pdf/2310.08319.pdf)

## LLM plus Retrieval

- [Making Retrieval Augmented Generation Better with @jamesbriggs](https://www.youtube.com/watch?v=Q-uEhJMu3ak)
- [Harnessing Retrieval Augmented Generation With Langchain](https://betterprogramming.pub/harnessing-retrieval-augmented-generation-with-langchain-2eae65926e82)
- [Knowledge Retrieval Architecture for LLM‚Äôs (2023)](https://mattboegner.com/knowledge-retrieval-architecture-for-llms/)  
- [How do domain-specific chatbots work? An Overview of Retrieval Augmented Generation (RAG)](https://scriv.ai/guides/retrieval-augmented-generation-overview/)
- [LangChain "Advanced Retrieval" Webinar](https://www.crowdcast.io/c/kqz7nl8nps42)
- [TWIML-RAG - a TWIML generative_ai community project.](https://github.com/TWIML/TWIML-RAG)

## Evaluating LLM plus Retrieval

- [Evaluation & Hallucination Detection for Abstractive Summaries](https://eugeneyan.com/writing/abstractive/) 
- [Building And Troubleshooting An Advanced LLM Query Engine](https://www.youtube.com/watch?v=_zDDErOaUqc)
- [Advanced RAG 02 - Parent Document Retriever](https://www.youtube.com/watch?v=wQEl0GGxPcM)

## LLM Inference

- [Easy-to-use headless React Hooks to run LLMs in the browser with WebGPU. As simple as useLLM().](https://github.com/r2d4/react-llm)
- [Inference Experiments with LLaMA v2 7b](https://github.com/djliden/inference-experiments/tree/main/llama2)  
- [OpenAI's Code Interpreter in your terminal, running locally](https://github.com/KillianLucas/open-interpreter)
- [Discover, download, and run local LLMs](https://lmstudio.ai/)

## LLM Data

- [Want High Performing LLMs? Hint: It is All About Your Data](https://home.mlops.community/home/videos/want-high-performing-llms-hint-it-is-all-about-your-data)
- [How LlamaIndex Can Bring the Power of LLM's to Your Data](https://drive.google.com/file/d/1qo_DqCilZdtCyQE1dpdJeJnav0fgunax/view) 
- [How to Create Custom Datasets To Train Llama-2](https://www.youtube.com/watch?v=z2QE12p3kMM)
- [Data Copilot](https://github.com/Modulos/data_copilot)

## LLM Observability  

- [AI Observability & Evaluation - Evaluate, troubleshoot, and fine tune your LLM, CV, and NLP models in a notebook.](https://github.com/Arize-ai/phoenix)

## LLM Opinions and Critiques  

- [Why Chatbots Are Not the Future](https://wattenberger.com/thoughts/boo-chatbots)

## LLM Tutorials and Courses  

- [Finetuning Large Language Models](https://www.deeplearning.ai/short-courses/finetuning-large-language-models/)
- [Large Language Models with Semantic Search](https://www.deeplearning.ai/short-courses/large-language-models-semantic-search/)
- [How Business Thinkers Can Start Building AI Plugins With Semantic Kernel](https://www.deeplearning.ai/short-courses/microsoft-semantic-kernel/)
- [LLM Bootcamp - Spring 2023](https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/)
- [LLM Bootcamp - Spring 2023](https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/)
- [Generative AI for Beginners - A Course](https://github.com/microsoft/generative-ai-for-beginners/tree/main)
- [Artificial Intelligence for Beginners - A Curriculum](https://github.com/microsoft/ai-for-beginners)
- [Introduction to Deep Learning](https://sebastianraschka.com/blog/2021/dl-course.html#l19-self-attention-and-transformer-networks)  

## LLM Engineering

- [Reflections on AI Engineer Summit 2023](https://eugeneyan.com/writing/aieng-reflections/)
- [AI Engineer Summit - Building Blocks for LLM Systems & Products](https://eugeneyan.com/speaking/ai-eng-summit/)

## LLM Engineering Best Practices  

- [All the Hard Stuff Nobody Talks About when Building Products with LLMs](https://www.honeycomb.io/blog/hard-stuff-nobody-talks-about-llm)
- [Building Defensible Products with LLMs](https://drive.google.com/file/d/1AOX4urZL1ac20MhnvEY2saDUmyR2vAOD/view)  
- [What Is ChatGPT Doing ... and Why Does It Work?](https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/)  
- [Interpretable Machine Learning: Fundamental Principles and 10 Grand Challenges](https://arxiv.org/abs/2103.11251)

## Open LLM Models

- [LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/abs/2302.13971?utm_source=www.turingpost.com&utm_medium=newsletter&utm_campaign=where-are-you-in-fmops-infrastructure-stack-tell-us)
- [BLOOM: A 176B-Parameter Open-Access Multilingual Language Model](https://arxiv.org/pdf/2211.05100.pdf?utm_source=www.turingpost.com&utm_medium=newsletter&utm_campaign=where-are-you-in-fmops-infrastructure-stack-tell-us)  

## Open LLM Tools  

- [LangChain: Enabling LLMs to Use Tools](https://drive.google.com/file/d/1Z9wxwZRG8JOMkUfwDw7fD8sbijQ32J7W/view)
- [Langchain Tutorials](https://github.com/gkamradt/langchain-tutorials)
- [LangChain cookbook](https://github.com/langchain-ai/langchain/tree/master/cookbook)
- [fairseq2](https://github.com/facebookresearch/fairseq2)
- [seamless_communication](https://github.com/facebookresearch/seamless_communication)

## Self-Hosted LLMs

- [Why host your own LLM?](http://marble.onl/posts/why_host_your_own_llm.html)   
- [How is LLaMa.cpp possible?](https://finbarr.ca/how-is-llama-cpp-possible/)
- [Discover, download, and run local LLMs](https://lmstudio.ai/)

## LLM Deployment

- [Deploying AI-driven apps on Vercel](https://vercel.com/blog/deploying-ai-applications)  
- [Solving the Last Mile Problem of Foundation Models with Data-Centric AI](https://home.mlops.community/home/videos/solving-the-last-mile-problem-of-foundation-models-with-data-centric-ai)
- [Taking LangChain Apps to Production with LangChain-serve](https://drive.google.com/file/d/14AY8DUlgvaLy73XOffYuTrqaweA2NH9w/view)

## LLM Infrastructure 

- [Age of Industrialized AI](https://docs.google.com/presentation/d/1yOwISoa-ujVK5ImC1aP2JoJslVWAe4GsQlih29TTQ5g/edit#slide=id.g2078c9f2667_0_62)
- [DevTools for Large Language Models: Unlocking the Future of AI-Driven Applications](https://docs.google.com/presentation/d/1kML0Q7CnRPp1eEByGqziGOpvGlcQD8j-/edit#slide=id.p1)
- [Large Language Model at Scale](https://home.mlops.community/home/videos/large-language-model-at-scale)

## LLM Events

- ["AI Agents Hackathon Develop your own AI agent within 48 hours!"](https://lablab.ai/event/ai-agents-hackathon)

## LLM Numbers 

- [Numbers every LLM Developer should know](https://github.com/ray-project/llm-numbers)

## LLM Hype  

- [Anti-hype LLM reading list](https://gist.github.com/veekaybee/be375ab33085102f9027853128dc5f0e)
- [ChatGPT Resources](https://gist.github.com/veekaybee/6f8885e9906aa9c5408ebe5c7e870698)

## LLM Newsletters

- [‚ú® Flashier Attention, ü§ê Gzip Classifiers](https://nlpnewsletter.substack.com/p/flashier-attention-gzip-classifiers)

## LLM Ethics and Governance   

- [Constitutional AI: Harmlessness from AI Feedback](https://arxiv.org/abs/2212.08073?utm_source=www.turingpost.com&utm_medium=newsletter&utm_campaign=where-are-you-in-fmops-infrastructure-stack-tell-us)
- [A guidance language for controlling large language models.](https://github.com/guidance-ai/guidance)

## LLM Startups and Funding  

- [The AI Startup Litmus Test](https://www.nfx.com/post/ai-startup-litmus-test)
- [Generative AI Strategy](https://huyenchip.com/2023/06/07/generative-ai-strategy.html) 
- [Lessons from 139 YC AI startups (S23)](https://www.reddit.com/r/ycombinator/comments/16h9lxu/lessons_from_139_yc_ai_startups_s23/?share_id=FzwJ8S6GOz1SkuG9WDY8y&utm_content=2&utm_medium=ios_app&utm_name=ioscss&utm_source=share&utm_term=1)

## LLM Business  

- [2023: The State of Generative AI in the Enterprise](https://menlovc.com/2023-the-state-of-generative-ai-in-the-enterprise-report/)  
- [Takeaways & lessons from 250k+ LLM calls on 100k corporate docs](https://www.credal.ai/blog/takeaways-from-using-llms-on-corporate-documents)

## LLM Marketing  

- [Your Success with Generative AI May Come Down to These UX Decisions](https://www.emcap.com/thoughts/your-success-with-generative-ai-may-come-down-to-these-ux-decisions/)

## Uncategorized
	https://github.com/yeagerai/yeagerai-agent
	https://github.com/homanp/superagent
	https://github.com/homanp/langchain-ui
	https://github.com/0xpayne/gpt-migrate
	https://github.com/shinework/photoshot
	https://arxiv.org/abs/2201.11903
	https://arxiv.org/abs/2210.03629
	https://arxiv.org/abs/2303.11366
	https://arxiv.org/abs/2305.10601
	https://news.ycombinator.com/item?id=36645575
	https://github.com/prefecthq/marvin
	https://github.com/eth-sri/lmql
	https://arxiv.org/pdf/2212.06094.pdf
	https://github.com/mlc-ai/web-llm
	https://github.com/Atome-FE/llama-node
	https://github.com/go-skynet/LocalAI
	https://localai.io
	https://www.cursor.so/blog/llama-inference
	https://www.geoffreylitt.com/2023/03/25/llm-end-user-programming.html
	https://every.to/chain-of-thought/what-comes-after-saas
	https://github.com/axilla-io/axgen
	https://www.axilla.io/
	https://github.com/f/awesome-chatgpt-prompts/blob/main/README.md
	https://magrawala.substack.com/p/unpredictable-black-boxes-are-terrible
	https://dl.acm.org/doi/10.1145/267505.267514
	https://www.youtube.com/@gklitt/videos
	https://www.inkandswitch.com
	https://idl.cs.washington.edu/files/2019-AgencyPlusAutomation-PNAS.pdf
	https://simonwillison.net/2023/Mar/27/ai-enhanced-development/
	https://www.robinsloan.com/notes/home-cooked-app/
	https://dl.acm.org/doi/10.1145/2593882.2593896
	https://wattenberger.com/thoughts/boo-chatbots
	https://www.geoffreylitt.com/2023/07/25/building-personal-tools-on-the-fly-with-llms.html
	https://web.mit.edu/6.031/www/sp22/
	https://www.youtube.com/watch?v=bJ3i4K3hefI
	https://github.com/tianlinxu312/Everything-about-LLMs 
